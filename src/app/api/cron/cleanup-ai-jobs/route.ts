import { NextRequest, NextResponse } from 'next/server';
import { db } from '@/config/firebase';
import { 
  collectionGroup,
  query, 
  where, 
  getDocs, 
  updateDoc,
  doc,
  Timestamp,
  serverTimestamp,
  startAfter,
  limit,
  QueryDocumentSnapshot
} from 'firebase/firestore';
import { activeJobsService } from '@/services/activeJobsService';
import { aiSummaryService } from '@/services/aiSummaryService';
import { contentRepurposeService } from '@/services/contentRepurposeService';

/**
 * Cleanup cron for AI features (AI Summary + Content Repurpose)
 * Uses activeJobs collection for efficient queries (98% cost reduction)
 * Handles batch processing for 10K+ user scale
 */
class AICleanupService {
  private readonly TIMEOUT_MINUTES = 5; // AI jobs are fast, 5 min timeout is sufficient
  private readonly MAX_RETRIES = 3;
  private readonly BATCH_SIZE = 500;

  async cleanupStalledAIJobs(): Promise<{
    cleaned: number;
    failed: number;
    retried: number;
    movedToDeadLetter: number;
    errors: string[];
  }> {
    console.log('üßπ Starting cleanup of stalled AI jobs using activeJobs collection...');
    
    const results = {
      cleaned: 0,
      failed: 0,
      retried: 0,
      movedToDeadLetter: 0,
      errors: [] as string[]
    };

    try {
      const timeoutThreshold = new Date();
      timeoutThreshold.setMinutes(timeoutThreshold.getMinutes() - this.TIMEOUT_MINUTES);
      const timeoutTimestamp = Timestamp.fromDate(timeoutThreshold);

      // Query activeJobs for AI features (ai-summary and content-repurpose)
      let lastDoc: QueryDocumentSnapshot | null = null;
      let hasMore = true;

      while (hasMore) {
        try {
          let stalledQuery = query(
            collectionGroup(db, 'activeJobs'),
            where('featureType', 'in', ['ai-summary', 'content-repurpose']),
            where('status', '==', 'processing'),
            where('createdAt', '<', timeoutTimestamp),
            limit(this.BATCH_SIZE)
          );

          if (lastDoc) {
            stalledQuery = query(
              collectionGroup(db, 'activeJobs'),
              where('featureType', 'in', ['ai-summary', 'content-repurpose']),
              where('status', '==', 'processing'),
              where('createdAt', '<', timeoutTimestamp),
              startAfter(lastDoc),
              limit(this.BATCH_SIZE)
            );
          }

          const stalledSnapshot = await getDocs(stalledQuery);

          if (stalledSnapshot.empty) {
            hasMore = false;
            break;
          }

          console.log(`üìä Processing batch of ${stalledSnapshot.size} stalled AI jobs...`);

          for (const jobDoc of stalledSnapshot.docs) {
            const jobData = jobDoc.data();
            const userId = jobData.userId || jobDoc.ref.parent.parent?.id;
            const jobId = jobData.jobId || jobDoc.id;
            const featureType = jobData.featureType as 'ai-summary' | 'content-repurpose';
            
            if (!userId || !jobId || !featureType) {
              console.warn(`‚ö†Ô∏è Skipping job with missing data:`, jobDoc.id);
              continue;
            }

            const retryCount = jobData.retryCount || 0;
            const maxRetries = jobData.maxRetries || this.MAX_RETRIES;

            try {
              if (retryCount < maxRetries) {
                // Retry the job
                console.log(`üîÑ Retrying stalled ${featureType} job: ${userId}/${jobId} (attempt ${retryCount + 1}/${maxRetries})`);
                
                // Update main record
                if (featureType === 'ai-summary') {
                  await aiSummaryService.updateAISummaryRecord(jobId, {
                    status: 'queued',
                    retryCount: retryCount + 1,
                    error: `Job timeout - retrying (attempt ${retryCount + 1}/${maxRetries})`
                  }, userId);
                } else {
                  await contentRepurposeService.updateContentRepurposeRecord(jobId, {
                    status: 'queued',
                    retryCount: retryCount + 1,
                    error: `Job timeout - retrying (attempt ${retryCount + 1}/${maxRetries})`
                  }, userId);
                }

                // Update activeJobs
                await updateDoc(jobDoc.ref, {
                  status: 'queued',
                  retryCount: retryCount + 1,
                  error: `Job timeout - retrying (attempt ${retryCount + 1}/${maxRetries})`,
                  updatedAt: serverTimestamp()
                });

                results.retried++;
              } else {
                // Max retries exceeded - move to dead letter queue
                console.log(`‚ùå Max retries exceeded for ${featureType} job ${userId}/${jobId}, moving to dead letter queue`);
                
                await this.moveToDeadLetterQueue(userId, jobId, jobData, featureType, `Job timeout - exceeded ${this.TIMEOUT_MINUTES} minutes and max retries (${maxRetries})`);
                
                // Update main record
                if (featureType === 'ai-summary') {
                  await aiSummaryService.updateAISummaryRecord(jobId, {
                    status: 'failed',
                    error: `Job timeout - exceeded ${this.TIMEOUT_MINUTES} minutes and max retries (${maxRetries})`,
                    retryCount: retryCount
                  }, userId);
                } else {
                  await contentRepurposeService.updateContentRepurposeRecord(jobId, {
                    status: 'failed',
                    error: `Job timeout - exceeded ${this.TIMEOUT_MINUTES} minutes and max retries (${maxRetries})`,
                    retryCount: retryCount
                  }, userId);
                }

                // Remove from activeJobs
                await activeJobsService.removeActiveJob(userId, jobId, featureType);

                results.movedToDeadLetter++;
                results.failed++;
              }
              
              results.cleaned++;
            } catch (updateError) {
              const errorMsg = `Error updating ${featureType} job ${userId}/${jobId}: ${updateError instanceof Error ? updateError.message : 'Unknown error'}`;
              console.error(`‚ùå ${errorMsg}`);
              results.errors.push(errorMsg);
            }
          }

          if (stalledSnapshot.size < this.BATCH_SIZE) {
            hasMore = false;
          } else {
            lastDoc = stalledSnapshot.docs[stalledSnapshot.docs.length - 1];
          }
        } catch (batchError) {
          const errorMsg = `Error processing batch: ${batchError instanceof Error ? batchError.message : 'Unknown error'}`;
          console.error(`‚ùå ${errorMsg}`);
          results.errors.push(errorMsg);
          hasMore = false;
        }
      }

      console.log(`‚úÖ AI cleanup complete: ${results.cleaned} jobs processed (${results.retried} retried, ${results.movedToDeadLetter} moved to dead letter)`);
      
      return results;
    } catch (error) {
      const errorMsg = `Fatal error during AI cleanup: ${error instanceof Error ? error.message : 'Unknown error'}`;
      console.error(`‚ùå ${errorMsg}`);
      results.errors.push(errorMsg);
      throw error;
    }
  }

  private async moveToDeadLetterQueue(
    userId: string, 
    jobId: string, 
    jobData: any, 
    featureType: string,
    reason: string
  ): Promise<void> {
    try {
      const { setDoc } = await import('firebase/firestore');
      const deadLetterRef = doc(collection(db, 'deadLetterQueue'));
      
      await setDoc(deadLetterRef, {
        originalJobId: jobId,
        userId: userId,
        featureType: featureType,
        jobData: jobData,
        reason: reason,
        movedAt: serverTimestamp(),
        retryCount: jobData.retryCount || 0,
        maxRetries: jobData.maxRetries || this.MAX_RETRIES
      });

      console.log(`‚úÖ Moved ${featureType} job ${userId}/${jobId} to dead letter queue: ${deadLetterRef.id}`);
    } catch (error) {
      console.error(`‚ùå Error moving job to dead letter queue:`, error);
    }
  }
}

const aiCleanupService = new AICleanupService();

/**
 * API route for cron job to clean up stalled AI jobs
 * Should run every 2-5 minutes (AI jobs are faster than STT)
 */
export async function GET(request: NextRequest) {
  try {
    // Verify cron secret
    const authHeader = request.headers.get('authorization');
    const cronSecret = process.env.CRON_SECRET;
    
    if (cronSecret && authHeader !== `Bearer ${cronSecret}`) {
      const querySecret = request.nextUrl.searchParams.get('secret');
      if (querySecret !== cronSecret) {
        return NextResponse.json(
          { error: 'Unauthorized' },
          { status: 401 }
        );
      }
    }

    console.log('‚è∞ Cron job triggered: Cleaning up stalled AI jobs...');
    
    const results = await aiCleanupService.cleanupStalledAIJobs();

    return NextResponse.json({
      success: true,
      message: 'AI cleanup completed',
      results: {
        cleaned: results.cleaned,
        retried: results.retried,
        failed: results.failed,
        movedToDeadLetter: results.movedToDeadLetter,
        errors: results.errors.length > 0 ? results.errors : undefined
      },
      timestamp: new Date().toISOString()
    }, { status: 200 });
  } catch (error) {
    console.error('‚ùå Error in AI cleanup cron job:', error);
    
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error',
      timestamp: new Date().toISOString()
    }, { status: 500 });
  }
}

// Also support POST for external cron services
export async function POST(request: NextRequest) {
  return GET(request);
}

